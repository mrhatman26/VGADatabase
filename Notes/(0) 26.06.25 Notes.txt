Each game is held in an anchor element with each anchor element being children
of the divider with an id of "search_resultsRows". 
Each anchor element has classname of "search_result_row ds_collapse_flag_
app_impression_tracked" (Needs investigating though because when I loaded the
page before, the app_impression_tracked part was not in the classname????)

Each anchor element also has a child span element which holds the title of the
video game. So, I use that to display in the console what the next game is.
(Idea: Have a custom print function that can be supressed if debug is false or
something like that)

Going to investigate this further.

Adding the app_tracked part to the anchor classname search returns nothing.
Odd.

09:49: Okay, so the scraping program can find the anchor elements needed to
open video game pages later and can also find the span elements that hold the
titles. However, I've already ran into the problem I was worried about:
Infinite scrolling. On the all games page as it is now, the last game is
"Planet Zoo". When in a browser, the user would just simply scroll down to
this game and the page would load more. However, requests is static and only
calls the page once. Research time...

9:58: Based off of some quick research at
https://scrapeops.io/python-web-scraping-playbook/python-scroll-infinite-pages/
XHR requests might be the key. Everytime the Steam all games page gets to the
bottom of the page, it makes an XHR rquest to the following URL
https://store.steampowered.com/search/results/?query&start=50&count=50&dynamic_data=&sort_by=_ASC&supportedlang=english&snr=1_7_7_230_7&infinite=1
The start number and counter number both being 50 got me to test how many
games that requests gets. The total (when starting at 1) was 51, so when
starting at 0, we get 50 instead. I think this might be the key where I have
it go through 50 games, then go to that URL at first, but add 50 every time
50. If this works, I foresee a red velvet cake in my future :)
