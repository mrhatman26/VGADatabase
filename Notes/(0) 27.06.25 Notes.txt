14:15: After experimenting with saving the JSON file from the requests, I
noticed that it is formatted as three lines. Line 1 is the opening bracket,
line 2 is a key called "success" which has the value of 1 and line 3 is... All
of the HTML. All of it. So, when getting the JSON file, I simply use
dictionary syntax to get the HTML which results in the line of:
HTML = main_page.json()["results_html"]
Then, using BeautifulSoup, it makes the HTML look like the HTML from calling
the normal search page URL. But I did not check for if it has the correct
ID/Class names. 
Overall, it looks like it'd be best not to use the normal search page and
instead use the XHR requests right off the bat. Let's see how this goes, eh?

14:27: It worked! It now successfully gets the next batch of games and is also
able to get the links to each game. Now the next part might be the hard part
as it involves going to each game page and getting the information from there.
But before that, I am going to implement a custom print function that can be
surpressed.

14:36: Implemented custom print function called "cprint". It takes one
parameter which is the text intended to be printed along with three optional
parameters which are: surpress which does not print if true, end_para which is
used to tell Python want to put at the end of a print and flush_para which
flushes the text buffer. The flush value won't be useful in the scraping
program, but it is useful in Flask which only prints consitently if flush is
set to true. Anyway, onto reading each page.

14:48: Not really noteworthy, but I just found out something I should have
already known about Python. If a variable is declared BEFORE a function, then
that function can access it. Really useful actually.

15:10: Okay, so let's plan what I want to collect from the page:
Let's go for the following and try and keep it simple:
1: Title
2: Description
3: Release Date
4: Developer
5: Publisher
6: Popular User Defined Tags (As a sublist)
7: The Price (Problem: Games have other products listed on their pages, so it
might be best to get the price from the main page rather than the game's page)
8: Game Features List (Sublist again)
9: Supported Languages (Maybe? I'll save this 'till last)
10: Genres
That is a lot to collect and might make this a slow process, but let's see how
this goes...

15:56: Okay, suspiciously easy thus far... I've got the program to get the
game's description and release date (along with the price and title given from
the parent page). The description contained both a new line and a truncate
(tab) so it took me a while to fix that by simply replacing them. Let's get
the other stuff done. Will I finish them by the end of today? Probably not!

16:12: After some fiddling around with the has_attr method, I found that I
could use the href to distinguish between the publisher and developer as the
href either contains /developer/ or /publisher/. As for the has_attr method,
it seems really useless? Sometimes it won't detect an attribute when a tag has
it and I cannot find a reason as to why... Maybe my own stupidity?

16:38: User tags can now be collected. And I've learned yet another basic
thing about Python... Strings can have special characters and whitespace
removed with the strip() method. Some of the tags were empty, white space or a
plus (a button I presume) and so this helped with that a lot. This took a bit
longer that I thought it would. I'm going to stop working at 5 and maybe do
more stuff later. For now though, on to the other data!
